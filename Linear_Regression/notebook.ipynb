{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised Machine Learning\n",
    "# Creating / training a model to find output with given outputs\n",
    "# It can be either Classification(isORnot) or Regression(what) \n",
    "# Common algorithms are Decision Trees , Linear regression , Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2daf83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised Machine Learning\n",
    "# No correct answers provided during training\n",
    "# It is like exploring the dataset to find what is interesting about it\n",
    "# It can either with Clustering (grouping similar items together) or Dimensionality Reduction (finding important features)\n",
    "# Common algorithms like K-means clustering , Hierarchial clustering and Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db5759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "# finding linear relationship between inputs and outputs \n",
    "#   y^ = wT.x + c\n",
    "\n",
    "\n",
    "# Cost function : How far our predictions are from the actual values \n",
    "# Mean Squared Error: (Summation(y^ - yi)^2)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc676b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent: Iteratively update weights/parameters to minimize the cost function /loss\n",
    "# Annealing : Changing learning rate after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2740512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w = 0, b = 0\n",
    "# For each iteration (epoch):\n",
    "#     For each sample i:\n",
    "#         Compute prediction: ŷ^(i) = w·x^(i) + b\n",
    "#         Compute error: error^(i) = ŷ^(i) - y^(i)\n",
    "    \n",
    "#     Compute gradients:\n",
    "#         dw = (2/m) x Σ(error^(i) x x^(i))\n",
    "#         db = (2/m) x Σ(error^(i))\n",
    "    \n",
    "#     Update parameters:\n",
    "#         w = w - a x dw\n",
    "#         b = b - a x db\n",
    "    \n",
    "#     Compute cost: J = (1/m) x Σ(error^(i))²\n",
    "    \n",
    "#     If cost converged or max iterations reached, stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c61f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalutation metrics\n",
    "# MAE (Mean Absolute Error) := (Summation|yi - y^i|)/m\n",
    "# RMSE (Root mean squared error) := (UnderRoot(MSE))\n",
    "# R-squared = 1 - ((Error of the prediction with original output)/(Error of the original output with respect to mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061aca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting := Model fits training data too well and performs poorly on new data\n",
    "# Under Fitting := Model is too simple and does not capture the relationship\n",
    "# Learning Rate: More the learning rate cause oscillations and too low causes low convergence"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
